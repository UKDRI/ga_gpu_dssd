#+title: GPU-Accelerated DSSD and Biological Validation Pipeline
#+author: Sam Neaves
#+date: <2025-11-28>
#+options: toc:2 num:nil
#+property: header-args :eval never-export

* Project Goal

This project implements a high-performance computational pipeline to identify and characterize heterogeneity in Parkinson's Disease (PD) using single-cell RNA-seq data.

The pipeline operates in three phases:
1.  **Discovery (GPU):** Uses a custom parallel Genetic Algorithm (GA) to discover "Diverse Subgroup Sets"â€”combinatorial rules that define distinct cell states.
2.  **Characterization (CPU):** Performs Differential Enrichment Analysis to determine the biological context (e.g., fibrosis, metabolic stress) of the discovered states.
3.  **Validation (GPU/CPU):** Uses "Shadow Runs" (blinded re-discovery) and external Pathway Analysis (GO/Enrichr) to prove robustness and biological relevance.

* Phase 1: Genetic Algorithm (Subgroup Discovery)

** Statistical Method: Time-Limited Random-Restart Permutation Test

To find the best possible solution and ensure its statistical significance, we employ a "random-restart" strategy combined with a massive permutation test.

-   **The Array Job:** The =simple_ga.sh= script launches a SLURM job array of 100 tasks (Task 0 for real data, Tasks 1-99 for permuted data).
-   **The Time Budget:** Each task runs for a fixed wall-clock time (e.g., 36 hours for deep search, 10 hours for validation).
-   **The "Random-Restart" Loop:** Inside the time window, the GA performs hundreds of independent restarts to explore the landscape globally.
-   **The Final p-value:** We compare the fitness of the "Champion" rule set found in the real data against the distribution of champions found in the 99 null (permuted) datasets.

** Key GA Parameters

-   =population_size = 55=: Optimized to fit within the ~128GB VRAM of Intel PVC GPUs using =int8= tensor operations.
-   =num_generations = 300=: Depth of a single local search.
-   =JOB_TIME_MINS=: The "breadth" of the search (total duration).

* Phase 2: Biological Characterization (Phase 1.5)

Instead of traditional "black box" rule extraction, this phase determines the *mechanism* of the discovered subgroups.

** Differential Enrichment Analysis

We define a "Subgroup" based on the GA rule (e.g., =PALD1=1=) and compare it against the background population to find co-expressed genes.

-   **Internal Validation (PD vs PD):** Compares Subgroup cells to other PD cells. This identifies the specific "Failure Mode" (e.g., why is *this* PD cell different from *that* PD cell?).
-   **External Validation (CTRL vs CTRL):** Checks if the subgroup exists in healthy controls and whether it exhibits the same pathological markers (e.g., LINGO1/Fibrosis).

** Pathway Validation (ORA)

We use =gseapy= to map the differentially enriched gene lists to the **Gene Ontology (GO)** and **Jensen DISEASES** databases. This provides objective, literature-backed confirmation of the biological state (e.g., "Mitochondrial Myopathy", "Extracellular Matrix Organization").

* Phase 3: The "Shadow Run" Validation

To test for biological redundancy and "Table Mountain" landscapes, we perform a **Shadow Run**.

1.  **Blinding:** We remove all genes associated with the primary discovery (e.g., PALD1, FTH1, NCOR2) from the dataset.
2.  **Re-Discovery:** We re-submit the GPU GA on this "scorched earth" dataset.
3.  **Inference:**
    -   If the GA fails to find a signal -> The primary discovery is unique.
    -   If the GA finds a new signal -> We have identified a secondary, redundant disease mechanism hidden by the primary signal.

* File Descriptions

** Core GA Files (GPU)

| File | Description |
| :--- | :--- |
| =simple_ga.sh= | Main wrapper. Launches the array and automatically submits the gather job. |
| =run_ga_array.slurm= | SLURM script for the main 100-job array. Sets up the =pytorch-gpu= environment. |
| =simple_ga_array.py= | Core Python GA worker. Runs the time-limited restart loop. |
| =ga_utils.py= | Shared utility functions for rule decoding and stats. |
| =run_gather.slurm= | Post-processing job. Collects results and calculates p-values. |
| =gather_results.py= | Analyzes raw results, generates Histograms and Subgroup Plots. |

** Analysis & Validation Files (CPU)

| File | Description |
| :--- | :--- |
| =analyze_subgroups_full.py= | Performs Differential Enrichment Analysis for both PD and Control populations. Generates CSVs of co-expressed genes. |
| =validate_biology.py= | Uses =gseapy= to query Gene Ontology databases for the gene lists found above. |
| =replot.py= | Utility to generate polished publication-quality figures from text summaries. |

** Shadow Run Files (Validation)

| File | Description |
| :--- | :--- |
| =shadow_ga.py= | Modified GA script that points to the =sc_data_blinded= directory. |
| =run_shadow.slurm= | SLURM script for the validation run (typically 100 jobs, 10 hours). |

* How to Run the Full Pipeline

** Step 1: Run the Phase 1 GA (Discovery)

#+begin_src bash
# Launch the 36-hour production run (100 jobs)
./simple_ga.sh ./results_prod_run --time=36:00:00
#+end_src

*Output:* =final_summary.txt= (Rules), =fitness_histogram.png= (Stats).

** Step 2: Characterize the Biology (Phase 1.5)

Run this on the login node or locally (CPU only). It requires =sc_data/X_binary.csv=.

#+begin_src bash
# 1. Generate Enrichment Tables (PD and CTRL comparison)
python3 analyze_subgroups_full.py

# 2. Validate against Gene Ontology
python3 validate_biology.py
#+end_src

*Output:* =enrichment_*.csv= and =pathway_validation_*.csv=.

** Step 3: Run the Shadow Validation

First, create the blinded dataset (removing top hits):

#+begin_src python
# (Run snippet to drop columns PALD1, FTH1, etc. and save to sc_data_blinded/)
#+end_src

Then submit the Shadow Run:

#+begin_src bash
sbatch run_shadow.slurm
#+end_src

*Output:* A new set of results in =shadow_results/= proving the existence (or absence) of secondary mechanisms.
