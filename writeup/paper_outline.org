#+title: A Rigorous, Interpretable Genetic Algorithm Framework Reveals Statistically Significant Gene Signatures in Parkinson's Disease Single-Cell Data
#+author: Sam Neaves
#+date: <2025-10-30>

* Abstract

- Background:
  Briefly state the challenge: Parkinson's Disease (PD) is
  heterogeneous, and single-cell (scRNA-seq) data offers a window into
  this, but discovering the complex, combinatorial gene patterns that
  define disease subgroups is difficult. Standard methods (like
  differential expression) are too simple, while "black-box" AI models
  (like deep learning) are not interpretable by biologists.
  

- Methodology:
  We applied an interpretable subgroup discovery framework using a
  Genetic Algorithm (GA) to a high-dimensional scRNA-seq dataset of
  dopaminergic neurons from PD patients and controls. Our method
  evolves sets of human-readable, IF-THEN logical rules to identify
  disease-associated subgroups.
  

- Rigor:
  To validate our findings and ensure they were not statistical
  artifacts from searching a high-dimensional space, we performed a
  massive-scale permutation test (1000 permutations). This involved
  over 200,000 independent GA runs and consumed ~10,000 GPU-hours on
  the DAWN supercomputer.
  

- Results:
  The GA identified a novel, non-obvious rule set (a combination of
  gene expression states) that was highly statistically significant
  (empirical p < 0.001). This rule set achieved a fitness on the real
  data that was not matched by any of the 999 permuted (randomized)
  datasets. The resulting rules point to a combinatorial signature
  involving genes such as [Gene A, Gene B, Gene C...].
  

- Conclusion:
  This work provides a statistically-validated, interpretable, and
  biologically relevant hypothesis for PD pathogenesis. It also
  demonstrates a powerful, generalizable framework for applying
  interpretable AI with large-scale HPC to extract robust, testable
  insights from complex single-cell data.

  
* Introduction

- The Biological Problem:
  Start with Parkinson's Disease. It's a complex, devastating
  neurodegenerative disease. Its progression and presentation are
  highly heterogeneous, suggesting multiple underlying mechanisms or
  patient subgroups.
  

- The Data Opportunity:
  The emergence of single-cell RNA sequencing (scRNA-seq) allows us,
  for the first time, to probe this heterogeneity at the resolution of
  individual cells, like the vulnerable dopaminergic neurons.
  

- The "Interpretability Gap" (Your Justification):
  This is your key argument.

  State that simple statistical methods (like differential gene
  expression) are useful but limited, as they only find individual
  gene changes and miss the combinatorial logic of biological
  pathways.
  

  State that "black-box" machine learning (e.g., Deep Learning, SVMs)
  can be highly predictive but fail to provide interpretable
  insights. A 95% accurate model is useless to a biologist if it
  cannot explain why it made its decision.
  

  This creates a need for methods that are both powerful (can search
  high-dimensional, combinatorial spaces) and interpretable (produce
  human-readable, testable hypotheses).
  

- Our Framework (GA + Rigor):
  Introduce your solution.
  Propose the use of a rule-based Genetic Algorithm, a class of
  evolutionary algorithm well-suited for complex combinatorial
  optimization. Our framework is specifically designed for Diverse
  Subgroup Set Discovery (DSSD). We hypothesize that Parkinson's is
  not a monolithic disease but a heterogeneous condition with
  multiple, distinct dysfunctional cell states. Therefore, unlike
  standard methods that find a single 'best' rule, our GA evolves a
  set of rules, where the entire set is evaluated for quality and
  diversity. Each chromosome in our GA represents a model of this
  heterogeneity, with each rule potentially identifying a distinct
  biological subgroup. To validate these models, we paired the GA with a massive-scale permutation
test..."

  "Critically, we implemented this GA in PyTorch to leverage GPU parallelization, transforming the computationally infeasible task of a 1000-permutation test into a tractable one."

- Justify the GA:
  Explicitly state it was chosen because it produces interpretable IF-THEN rules that represent gene combinations.

- Justify the Rigor:
  State that to overcome the risk of "p-hacking" or finding spurious
  correlations in the high-dimensional data, you paired the GA with a
  massive-scale permutation test.
  

- Punchline:
  In this paper, we apply this rigorous, interpretable framework to a
  [Your Data] scRNA-seq dataset. We leverage the DAWN HPC system to
  perform ~10,000 GPU-hours of computation, resulting in the discovery
  of a statistically significant (p < 0.001) and interpretable gene
  signature for a PD subgroup.

* Methods

This section must be crystal clear and reproducible.

** Single-Cell Data Preprocessing:

- Source: Describe the SNatlas_DaNs_seurat.RData object.

- Filtering: Detail the cell filtering (e.g., keeping only CTR and PD labels PD_B5-6, PD_B3-4, resulting in 6,385 cells).

- Confounder Correction: State that you used SCTransform to normalize data and simultaneously regress out the donor batch effect (the Sample_v2 variable). This is crucial for rigor.

- Feature Selection: Explain that you performed a DE test on the corrected data and selected the top 1000 most variant genes for the GA, balancing computational feasibility with discovery.

- Binarization: Describe the z-scoring method ((expression - mean) / std_dev) and binarization (> 0 -> 1, <= 0 -> 0) to create the final 6385 x 1000 input matrix.

** The Genetic Algorithm Framework:

*** 

- Chromosome Representation: Explain that each "individual" is a chromosome representing a set of k rules (where k was 3-6). Explain the "mask + value" structure for each rule (e.g., 2 * 1000 = 2000 bits per rule).

- Fitness Function: This is critical. Define Fitness = Quality / Overlap.

- Explain Quality = WRAcc(Union(Rules)). Justify WRAcc as a metric that balances subgroup size (support) and accuracy (lift).

- Explain Overlap = TotalMatches / UniqueMatches as a penalty to encourage diverse, non-redundant rule sets.

- GA Parameters: State them clearly: population_size=55,
  num_generations=1000, tournament selection (size=5), single-point
  crossover, bit-flip mutation (rate=0.0001), elitism (count=2).

*** A Diverse Subgroup Set Discovery (DSSD) Fitness Function

Our primary goal was not to find the single *best* rule describing PD,
as this would ignore the known heterogeneity of the disease. Standard
subgroup discovery algorithms often suffer from redundancy, where the
top 10 "best" rules are trivial variations of each other, all
describing the same, largest subgroup.

To overcome this, we designed our framework for *Diverse Subgroup Set
Discovery (DSSD)*. The central hypothesis is that our GA chromosome,
as a set of rules:

\[
\{ \text{Rule}_1, \text{Rule}_2, \ldots, \text{Rule}_k \}
\]

can serve as an interpretable model of distinct cell states.

To force the GA to find such a set, we designed a custom,
set-based fitness function that simultaneously rewards both quality
(exploitation) and diversity (exploration):

\[
\text{Fitness} =
\frac{\text{Quality}\big(\text{Union}(\text{Rules})\big)}
     {\text{Overlap}(\text{Rules})}
\]

1. *Quality (WRAcc of the Union)*  
   The quality of a chromosome is measured by the Weighted Relative Accuracy (WRAcc)
   of the union of all cells covered by its rules.

   \[
   \text{WRAcc} = P(G) \times \big(P(\text{Class} \mid G) - P(\text{Class})\big)
   \]

   where \( G \) is the subgroup.  
   This metric balances *support* (the size of the total subgroup found, \( P(G) \))
   with *lift* (the enrichment of PD cells in that subgroup,
   \( P(\text{Class} \mid G) - P(\text{Class}) \)).
   It rewards chromosomes that identify a large and highly enriched population of PD cells.

2. *Diversity (Overlap Penalty)*  
   The denominator, *Overlap*, is a penalty for redundancy. It is defined as:

   \[
   \text{Overlap} = \frac{\text{TotalMatches}}{\text{UniqueMatches}}
   \]

   where *UniqueMatches* is the number of cells covered by the union (as in the quality metric),
   and *TotalMatches* is the sum of cells covered by each rule individually.
   If all rules in a set cover the exact same cells, the Overlap score will be high (equal to \( k \)),
   heavily penalizing the chromosome’s fitness.

*Interpretation:*  
This fitness function creates an evolutionary pressure that punishes redundant rule sets
and rewards sets where each rule identifies a different population of cells,
all while maintaining high overall enrichment for the PD phenotype.
A high-fitness chromosome is therefore interpreted as a model of distinct,
disease-associated cell states.

***

2.c. Scalable Implementation: A GPU-Accelerated Genetic Algorithm
While the DSSD fitness function defines what to find, a computationally efficient search algorithm is required to find it. Standard subgroup discovery implementations (e.g., in R or sequential Python) are often iterative, CPU-bound, and computationally slow. A single run on a dataset of this scale can take many minutes to hours.

This slowness makes a rigorous permutation test—which requires running the entire discovery process 1,000+ times—computationally infeasible.

To solve this, we adapted the DSSD framework to a Genetic Algorithm (GA), as the population-based nature of GAs is "embarrassingly parallel." We specifically designed our GA implementation to leverage massive GPU parallelization using PyTorch and the Intel Extension for PyTorch (IPEX).

The key adaptation was vectorizing the entire fitness calculation. Instead of iterating through each chromosome one by one, we:

Represented the entire population for a batch of permutations as a single large tensor [N, P, C], where N is the number of permutations (e.g., 16), P is the population size (e.g., 55), and C is the chromosome length.

Implemented the get_rule_matches function as a series of large-scale tensor broadcast operations. This creates a massive intermediate tensor ([N, P, R, S, F]) that allows the GPU to check every rule, for every chromosome, for every permutation, against every sample, for every feature simultaneously.

All subsequent calculations (WRAcc, overlap) were also performed as parallel tensor operations, resulting in a fitness score for every chromosome in the batch.

This GPU-accelerated design is the critical enabler of our study. It collapses the runtime for a single, complex DSSD run (e.g., 1000 generations, pop=55) from hours on a CPU to approximately 2-3 minutes on a single Intel Max 1550 GPU.

This massive speedup is what made our "best-of-N-repeats" permutation test, which consumed ~10,000 GPU-hours in total, computationally feasible. It allowed us to apply the same intense search effort (200 repeats * 1000 generations) to both the real data and all 999 permuted datasets, ensuring statistical rigor.

** Statistical Validation: The "Best-of-N-Repeats" Permutation Test:

This is your most impressive method. Explain it in detail.

- Null Hypothesis: That the observed gene expression patterns are not associated with the PD/CTR labels.

- Procedure: To test this, you created 1000 datasets (1 real + 999 permuted by shuffling labels).

- Rigor Justification: To ensure a fair comparison, the exact same computational effort was applied to every single dataset.

- Effort per Dataset: Define the effort: "Each of the 1000 datasets was searched by N=200 independent GA runs, each starting from a different random population. The single highest-fitness chromosome found across all 200 repeats was recorded as the 'best' result for that dataset."

- P-Value Calculation: The empirical p-value is (count(F_perm_i >= F_real) + 1) / (999 + 1).

* HPC Implementation:

- Briefly state the GA was implemented in Python using PyTorch/IPEX for GPU acceleration.

- Explain the experiment was executed as a 1000-task SLURM job array (--array=0-999) on the DAWN supercomputer.

- State the resource request (--time=10:00:00, --gres=gpu:1) and the
  total cost: "This comprehensive, statistically rigorous search
  consumed approximately 10,000 GPU-hours."
  


* Results
1. A Statistically Significant Signature is Discovered:

- State the main finding: "The 'best-of-200' search on the real data (Task 0) yielded a rule set with a fitness of [F_real]."

- "The distribution of 'best-of-200' fitness scores from the 999 permuted datasets had a mean of [Avg_F_perm] and a maximum of [Max_F_perm]."

- "No permuted dataset achieved a fitness as high as the real data. This yields an empirical p-value of p < 0.001 (0 observed / 999 permutations, +1/+1).

- THE FIGURE: You must include a histogram here. It will show the beautiful bell curve of the 999 permuted fitness scores, with a single red line for your F_real score sitting far to the right, all alone. This figure is the central proof of your paper.

2. The Interpretable PD Signature:

- Present the winning rule set (the Rank 1 rules from the ga_results_0.txt file).

- List the rules clearly:

- Rule 1: TPPP=0 AND SEC62=0 AND COX6C=0 ...

- Rule 2: NLGN4Y=0 AND COL5A1=0 ...

  ...

3. Subgroup Characterization (The so what):

Report the support (e.g., "This rule set identifies a subgroup of [X] cells...") and precision (e.g., "...of which [Y]% are PD cells, representing a [Z]-fold enrichment over baseline.")

(Optional, but powerful) Show a UMAP plot of all 6,385 cells, with the
cells identified by your rule set colored differently. Do they
cluster?

* Discussion

1. Summary of Findings: Re-state the main finding (a p < 0.001 interpretable signature was found) and emphasize that its strength comes from the combination of genes, not any single gene.

2. Biological Interpretation (Your collaboration): This is where you
   discuss the meaning of the genes in the rules. "The appearance of
   TPPP, COX6C, and [Gene X] in the top rules is highly
   suggestive... TPPP is involved in... COX6C is a component of... The
   fact that our model found a rule combining TPPP=0 (low) and COX6C=0
   (low) suggests a combinatorial failure in [X pathway]... This is a
   novel, testable hypothesis for a specific PD subgroup."

3. The DSSD Framework Successfully Modeled Heterogeneity:
   Our goal was not just to find a single signature, but to model PD's
   heterogeneity. The DSSD framework proved highly effective. The
   top-ranking chromosome (p < 0.001) consisted of 6 distinct rules
   (see Results, Table X). An analysis of these rules shows they are
   not redundant; they identify different, though potentially
   overlapping, subsets of the cell population.

   For example, Rule 1 (TPPP=0 AND COX6C=0 ...) points to a subgroup
   defined by [X genes, e.g., mitochondrial function], while Rule 3
   (COL16A1=0 AND SDC3=0 ...) identifies a different subgroup defined
   by [Y genes, e.g., extracellular matrix]. This provides a
   data-driven model of multiple potential dysfunctional states
   co-existing within the PD patient population. These distinct
   rule-defined subgroups can now be analyzed independently (e.g., via
   pathway analysis or visualization on the UMAP) to explore these
   different facets of the disease. This demonstrates the power of
   DSSD over simpler methods that would have missed this richness.

   A key contribution of this work is a scalable framework for
   rigorous DSSD. By adapting the DSSD concept to a fully vectorized,
   GPU-accelerated Genetic Algorithm, we demonstrated that large-scale
   permutation testing (consuming 10,000+ GPU-hours) is not only
   possible but necessary for validating findings in high-dimensional
   data. This HPC-centric approach provides a blueprint for future
   studies aiming to bridge the gap between interpretable AI and
   statistical robust ai.
   

4. Methodological Reflections (Your "Experience"):

- On Interpretability: Reiterate that this result is immediately useful to biologists, unlike a black-box model.

- On Rigor: Discuss the necessity of the 10,000-hour permutation test. Show the Avg_F_perm was non-zero, proving that even random data can produce seemingly good rules. This justifies the need for the massive computation to prove your real result was not random.

- On HPC: State that this level of statistical rigor, while computationally expensive, is now feasible on modern HPC platforms like DAWN and should be considered a new standard for AI-driven discovery in biomedicine.

5. Limitations: Be upfront.

- The search was limited to 1000 pre-selected genes.

- The binarization of data is a simplification.

- The results are a computational hypothesis, not a wet-lab-validated fact (this is the next paper).

* Conclusion:
  "We have successfully applied an interpretable, scalable, and
  statistically rigorous GA framework to discover a novel gene
  signature in PD. This work provides a concrete, data-driven
  hypothesis for PD researchers and serves as a powerful case study
  for the use of interpretable AI in complex biomedical discovery."
  

